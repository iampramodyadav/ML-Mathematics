{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68725fe2-1e35-43af-b4e9-470a8f0923be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb1375b5-2024-4365-8ab5-5b1414e2cf68",
   "metadata": {},
   "source": [
    "## Course 2: Calculus for Machine Learning and Data Science\r\n",
    "After completing this course, learners will be able to:\r\n",
    "- Analytically optimize different types of functions commonly used in machine learning using properties of derivatives and gradients\r\n",
    "- Approximately optimize different types of functions commonly used in machine learning using first-order (gradient descent) and second-order (Newton’s method) iterative methods\r\n",
    "- Visually interpret differentiation of different types of functions commonly used in machine learning\r\n",
    "- Perform gradient descent in neural networks with different activation and cost functions \r\n",
    "\r\n",
    "### Week 1: Functions of one variable: Derivative and optimization\r\n",
    "\r\n",
    "#### Lesson 1: Derivatives\r\n",
    "- Example to motivate derivatives: Speedometer\r\n",
    "- Derivative of common functions (c, x, x^2, 1/x)\r\n",
    "- Meaning of e and the derivative of e^x\r\n",
    "- Derivative of log x\r\n",
    "- Existence of derivatives\r\n",
    "- Properties of derivative\r\n",
    "- [Practice Quiz: Derivatives](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-1/C2_W1_Practice-Quiz.md)\r\n",
    "- [Lab: Differentiation in Python: Symbolic, Numerical and Automatic](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-1/C2_W1_Lab_1_differentiation_in_python.ipynb)\r\n",
    "\r\n",
    "#### Lesson 2: Optimization with derivatives\r\n",
    "- Intro to optimization: Temperature example\r\n",
    "- Optimizing cost functions in ML: Squared loss\r\n",
    "- Optimizing cost functions in ML: Log loss\r\n",
    "- [Quiz: Derivatives and Optimization](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-1/C2_W1_Quiz.md)\r\n",
    "- [Programming Assignment: Optimizing Functions of One Variable: Cost Minimization](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-1/C2_W1_Assignment.ipynb)\r\n",
    "\r\n",
    "### Week 2: Functions of two or more variables: Gradients and gradient descent\r\n",
    "\r\n",
    "#### Lesson 1: Gradients and optimization\r\n",
    "- Intro to gradients\r\n",
    "- Example to motivate gradients: Temperature\r\n",
    "- Gradient notation\r\n",
    "- Optimization using slope method: Linear regression\r\n",
    "- [Practice Quiz: Partial Derivatives and Gradient](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-2/C2_W2_Practice-Quiz.md)\r\n",
    "\r\n",
    "#### Lesson 2: Gradient Descent\r\n",
    "- Optimization using gradient descent: 1 variable\r\n",
    "- Optimization using gradient descent: 2 variable\r\n",
    "- Gradient descent for linear regression\r\n",
    "- [Lab: Optimization Using Gradient Descent in One Variable](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-2/C2_W2_Lab_1_Optimization_Using_Gradient_Descent_in_One_Variable.ipynb)\r\n",
    "- [Lab: Optimization Using Gradient Descent in Two Variables](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-2/C2_W2_Lab_2_Optimization_Using_Gradient_Descent_in_Two_Variables.ipynb)\r\n",
    "- [Quiz: Partial Derivatives and Gradient Descent](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-2/C2_W2_Quiz.md)\r\n",
    "- [Programming Assignment: Optimization Using Gradient Descent: Linear Regression](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-2/C2_W2_Assignment.ipynb)\r\n",
    "\r\n",
    "### Week 3: Optimization in Neural Networks and Newton’s method\r\n",
    "\r\n",
    "#### Lesson 1: Optimization in Neural Networks\r\n",
    "- Perceptron with no activation and squared loss (linear regression)\r\n",
    "- Perceptron with sigmoid activation and log loss (classification)\r\n",
    "- Two-layer neural network with sigmoid activation and log loss\r\n",
    "- Mathematics of Backpropagation\r\n",
    "- [Lab: Regression with Perceptron](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Lab_1_Regression_with_Perceptron.ipynb)\r\n",
    "- [Lab: Classification with Perceptron](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Lab_2_Classification_with_Perceptron.ipynb)\r\n",
    "- [Practice Quiz: Optimization in Neural Networks](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Practice-Quiz.md)\r\n",
    "\r\n",
    "#### Lesson 2: Beyond Gradient Descent: Newton’s Method\r\n",
    "- Root finding with Newton’s method\r\n",
    "- Adapting Newton’s method for optimization\r\n",
    "- Second derivatives and Hessians\r\n",
    "- Multivariate Newton’s method\r\n",
    "- [Lab: Optimization Using Newton's Method](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Lab_3_Optimization_Using_Newtons_Method.ipynb)\r\n",
    "- [Quiz: Optimization in Neural Networks and Newton's Method](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Quiz.md)\r\n",
    "- [Programming Assignment: Neural Network with Two Layers](https://github.com/Ryota-Kawamura/Mathematics-for-Machine-Learning-and-Data-Science-Specialization/blob/main/Course-2/Week-3/C2_W3_Assignment.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
